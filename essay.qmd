---
title: Celebrity Private Jet Data Analysis
jupyter: python3
---


### Julian Shah, Yunzhu Chen

## Introduction

Why should a select few be allowed to contribute so much more than others
to climate change compared to the average person? Simply because they
have more money? How much more do they contribute than the average person
anyway? Is it more nuanced than just 'the super rich'?

In this essay we seek to answer the last two questions. We will be analysing
the wealth of individuals who have private jets in comparison to their jet
usage, the kind of celebrity they are, and more so that people can be 
informed in their anger and have just one more - or less - reason to spite 
the uber rich.

We hope that one day, this essay will contribute to the monumental task of
regulating extreme wealth and exuberance so that we have a more fair 
society that doesn't burden the poor for a problem where the rich are
more responsible. 

The celebrities and data we use come from the leaderboard of
***[celebrityprivatejettracker.com](https://celebrityprivatejettracker.com/)***.
Please feel free to check out the site.


(In the introduction, you should aim to tell the reader what your
project is about. In doing so, you should answer the following
questions:

What is the question you are trying to answer or the story that you are
trying you tell? Why is this question or story important? What were the
main steps your project made towards answering the question or telling
the story? Beyond answering these questions, you are free to structure
this section however you wish.)

## Setup Instructions

Before we begin your rage fueled adventure please follow these simple
instructions. Don't worry, it won't take more than a few minutes.

**\*\*\*If you ever think about stopping half way, just think about the overbearing and
overzealous oligarchy that watches from above and you should find a renewed vigor 
sputter to life within you\*\*\***

caution: those around you may see fire in your eyes when you do this exercise


### Requirements

This project runs in Python 3.1x. Please ensure that you have an appropriate 
version of python installed and kernel selected (in VSCode you can choose your
kernel in the top right where it says \"select kernel\").

The requirements.txt file contains all the dependencies to run this project. To
install all the requirements, we will be using pip. Usually, pip comes preinstalled
with python. To check that you have pip run:

```
pip --version
``` 

in BASH shells (MacOS/Linux) or:

```
python -m pip --version
```

in Windows. On the off chance that you have python and not pip, please follow
[this guide from the pip documentation](https://pip.pypa.io/en/stable/installation/).

Once you have pip installed you can run
```
pip install -r requirements.txt
```
in BASH shells (MaxOS/Linux) or:
```
pip install --upgrade -r requirements.txt
```

### API Key

An API key from [api-ninjas.com](https://www.api-ninjas.com/) is required to run this 
project. You need to create an account to create your own API key. If you do not
already have an account you can create it [here](https://www.api-ninjas.com/register).

NOTE: The api key from api-ninjas has a max calls of 10000 per month. This essay uses
~70 every time it runs so consider changing 
```
GATHER_API_DATA = False
```
in order to stop calling the api after you've run it the first time.

Once you have your account you need to retrieve your key and place it within the 
keys.py file.

First, retrieve your key by copying it from the [api-ninjas profile page](https://www.api-ninjas.com/profile).
You will have to click 'Show API Key' to see and copy your key in the profile page.

Next, open the keys.py file and and paste your key in between the quotation marks,
replacing YOUR API KEY HERE with your key. It should go from this:
```
def get_ninja_key():
    return "YOUR API KEY HERE"
```
to something like this:
```
def get_ninja_key():
    return "ABC1234xyz7890-FAKEKEY0987654321"
```

The last thing you have to do is run the code cell below in order to get 
matplotlib, which we use for visualizations, to work.


```{python}
%matplotlib inline 
```

#### You are now ready to begin your journey!

## Methodology, Data Collection, & Processing

Here is all the data we got and used in this project.

**1) Celebrity Jet Usage** **Source:** Celebrity Jet Tracker Website
(https://celebrityprivatejettracker.com/) **Method:** Scrap/html â€¦?
**Process & Storage:** **Usage:**

**2) Celebrity Age and Occupation** **Source:** Wikipedia **Method:** We
got it directly from the Wikipedia website with several libraries,
including requests, wptools and mwparserfromhell. **Process & Storage:**
**Usage:**

**3) Celebrity Net Worth** **Source:** API Ninjas website **Method:**
**Process & Storage:** **Usage:**

**4) Oscar & Grammy Nominees** **Source:** Wikipedia **Method:** We got
it directly from the Wikipedia website with several libraries, including
requests, wptools and mwparserfromhell. **Process & Storage:**
**Usage:**

### Jet Data

This project is structured around data retrieved from 
[celebrityprivatejettracker.com](https://celebrityprivatejettracker.com/leadeerboard).
The leaderboard contains 63 celebrities with private jets (as of 03/27/2025) 
which we scraped using the python requests library.  
  
We put all of the retrieval code into ___manipulate_data.py___ so we start by
importing that. Then we can call the function
```
get_flighttracking()
```
which, by default, gets all of the html from the **https://celebrityprivatejettracker.com/leadeerboard**
site and writes it to ***./Data/data_flighttracker.html***

```{python}
import manipulate_data
manipulate_data.get_flighttracking()
```

If you'd like to see what the html looks like go to the file where it is saved.
It's quite long thought and pretty messy, which leads us to the next point: 
we've gotta clean our data.  
  
to accomplish this we are going to use another one of the handy, functions
we've writting in manipulate data. It's called
```
get_celeb_tracking()
```
This one uses beautifulsoup4, a powerful html parser, to put snippets of 
html for each celebrity into a list. It works well because the leaderboard
on celebrityjettracker is organized into a table so we can look for the
tag at the head of each row of the table. 

```{python}
celebrity_data_chunks = manipulate_data.get_celeb_chunks()
```

The next function we're going to run extracts the celebrity name and data from
the larger list of data chunks we give it. It returns a dictionary (which is a 
data type in python) so that we can begin visualizing the data.
```
get_celeb_data(celebrity_data_chunks)
```

```{python}
celebrity_data = manipulate_data.get_celeb_data(celebrity_data_chunks)
```

But wait! We can't acutally use this yet. Guess what, we've "hit a crucial part
of data analysis" (your professor says over your shoulder with a wild grin on
their face). 

Unfortunately, the data is not yet usable. We need to clean it. Now, we snuck in
some data cleaning already in the last function. Some of the scraped data contained
'Non-breaking' spaces which we needed to replace with normal spaces. Also, some
of the names we scraped were wrong and we replaced those.

That was light work though. Now it's time put on our rubber gloves and clean up
some mercury. This next function removes cleans our data so that we can access
the numbers to do our visualization. 
```
clean_all_data(celebrity_data_chunks)
```

Each pair will now be in this order
```
{"CELEBRITY NAME": ["Jet Model", "Tail Registration", "Total Miles Flown", "Total Flights", "Total Gallons of Fuel Used", "Total Hours of Flight", "Metric Tons of C02 Released"]}
```
and makes it into something like
```
{"Imaginary Celebrity": ["Learjet 60", "J420ET", "100000", "1", "1010", "0.1", "100000000000000000000000000000000000"]}
```

It does this for every celebrity.

Crucially, this changes the already existing dictionary so it doesn't need to be
set equal to a return value

```{python}
manipulate_data.clean_all_data(celebrity_data)
```

The final function we're going to run is a function that combines duplicates.
Many of the celebrities here are soooo wealthy that they own, or have owned,
multiple jets in their lifetime. In this case, we need to synchronise their
data using:
```
combine_duplicates(celebrity_data)
```

```{python}
accountable_data = manipulate_data.combine_duplicates(celebrity_data)
```

Yay! You've now got nicely formatted data to do some visualisations.

### API Ninjas Data

After all that work, you may be asking 'what about that API key you **made**
me retrieve earlier. Don't worry, we're getting to that now.

This API is used to get the net worth of celebrities through code. Transparently,
we don't actually know where this data is being sourced from. However, after
doing some simple cross referencing (make api call for net worth and compare
result to sites like Forbes.com net worth ranking) to determine this data
is accurate **enough** for fueling your rage (or not, we'll see).

This is actually



(In the methodology, you should explain how you obtained, processed, and
summarized or visualized the data. In doing so, you should answer the
following questions:

Where did you get your data from? How did you get this data (i.e., did
you programmatically download it or did you access it through an API)?
How did you store and/or process this data (e.g., did you store and
process it in Pandas)? What information did you get from this data that
you used in the presentation of your results?)


### Data Analysis and Visualization

How do we relate the data and use them

## Results

(In the results, you should show the main summaries or visualizations of
your data, along with any accompanying information. In doing so, you
should answer the following questions:

What summaries or visualizations did you create? What are the
interesting and/or important parts of these summaries or visualizations?
How do these results answer your questions or tell your story?)

### Visualizations

-   Pie chart of jet miles each owner
-   ??(some kind of graph) of carbon emissions rank of people who own
    more than one jet
-   Histogram of carbon emiisions by age
-   Histogram of carbon emissions by netÂ worth

potentially: - Pie chart of carbon emiisions by occupation - Carbon
emission among musicians (grammy nominees vs others) - Carbon emission
among actors (oscar nominees vs others)

### Summaries and Interpretation

## Conclusion

(In the conclusion, you should provide key takeaways for the reader. In
doing so, you should answer the following questions, where applicable:

What are the important insights that the reader should get from this
project? What are the ethical considerations surrounding the data
sourcing? What are the contextual or ethical implications of your topic
or work? What lessons did you learn as you did the project? What were
the most difficult, challenging, or frustrating parts of the project? In
what ways would you extend or change your project if you had more time?)

### Key Takeaways



### Ethical Considerations

Now, we are scraping. Scraping can be used in bad ways because it could 
take someone's free resource and be used for personal gain. In this case
however there is little personal gain (no fiscal output is retrieved
from this project)

### Challenges and Restrictions

Now, this list is a good general baseline but may not be super accurate.
For one, the data from api-ninjas is not from a clear source and cannot
be perfectly verified. For another, those super rich that really don't 
want their flights tracked can simple rent different private jets and 
switch often.

### Future Work

This project should expand at the same pace that celebrities are added to
the celebrityjettracker.com leaderboard. Since we are so heavily reliant
on it this project cannot be easily expanded. 

However, there are some avenues. For example, a deeper look into the data
could provide even more insights that we were able to find. One thing we
didn't look at is educational level. This project could be expanded in 
many ways and we are totally happy if you do so!

